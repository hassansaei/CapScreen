#!/usr/bin/env python3
"""
Quality Control (QC) script for CapScreen data.

This script parses HTML reports generated by the CapScreen pipeline and creates
QC summary plots including:
- Assembled reads by sample
- Q30 rate by sample
- Percentage of reads assigned to valid peptides by sample
"""

from __future__ import annotations

import logging
import re
from pathlib import Path
from typing import Any, Dict, List, Optional

import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend for saving plots
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

logger = logging.getLogger(__name__)

_INT_RE = re.compile(r"(\d[\d,]*)")
_FLOAT_RE = re.compile(r"[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?")


def _to_int(text: str) -> Optional[int]:
    """Extract integer from text string."""
    m = _INT_RE.search(text or "")
    if not m:
        return None
    return int(m.group(1).replace(",", ""))


def _to_float(text: str) -> Optional[float]:
    """Extract float from text string."""
    m = _FLOAT_RE.search(text or "")
    if not m:
        return None
    return float(m.group(0))


def _parse_value_before_slash(text: str) -> Optional[int]:
    """Parse value before slash, e.g. "4,667,643 / 4,673,204 (99.881%)" -> 4667643."""
    if not text:
        return None
    left = text.split("/", 1)[0]
    return _to_int(left)


def _read_all_tables(html_path: Path) -> List[pd.DataFrame]:
    """Read all HTML tables from a file."""
    return pd.read_html(str(html_path))


def _extract_sample_name_from_tables(tables: List[pd.DataFrame], fallback: str) -> str:
    """Extract sample name from tables, with fallback to filename."""
    return fallback


def _build_kv_maps_from_table(df: pd.DataFrame) -> Dict[str, List[str]]:
    """
    Convert a 2-column table into mapping: label -> [values...]
    Keeps duplicates (important for q30_rate appearing twice).
    """
    kv: Dict[str, List[str]] = {}
    if df.shape[1] < 2:
        return kv

    # normalize to first two columns
    col0 = df.iloc[:, 0].astype(str).tolist()
    col1 = df.iloc[:, 1].astype(str).tolist()

    for k, v in zip(col0, col1):
        k = (k or "").strip()
        v = (v or "").strip()
        if not k or k.lower() == "nan":
            continue
        kv.setdefault(k, []).append(v)
    return kv


def _find_after_filtering_q30_rate(html_text: str) -> Optional[float]:
    """
    Prefer q30_rate inside the 'FASTP (After Filtering)' section.
    Works on your example where headers are:
      <tr><th colspan="2">FASTP (After Filtering)</th></tr>
      ...
      <tr><td>q30_rate</td><td>0.960017</td></tr>
    """
    if not html_text:
        return None

    # Narrow to the block after the header until the next <tr><th colspan="2">...</th></tr>
    header_pat = re.compile(r"FASTP\s*\(After Filtering\)", re.IGNORECASE)
    m = header_pat.search(html_text)
    if not m:
        return None

    block = html_text[m.start():]
    # stop at the next section header (colspan)
    stop = re.search(r"<tr>\s*<th[^>]*colspan\s*=\s*['\"]?2['\"]?[^>]*>", block, flags=re.IGNORECASE)
    # The first match is the current header row itself, so search again after a bit.
    if stop:
        stop2 = re.search(
            r"<tr>\s*<th[^>]*colspan\s*=\s*['\"]?2['\"]?[^>]*>",
            block[stop.end():],
            flags=re.IGNORECASE,
        )
        if stop2:
            block = block[: stop.end() + stop2.start()]

    # Find the q30_rate row inside this block
    m2 = re.search(
        r">q30_rate<\s*/td>\s*<td>\s*(" + _FLOAT_RE.pattern + r")\s*<",
        block,
        flags=re.IGNORECASE,
    )
    if not m2:
        return None
    return float(m2.group(1))


def _parse_single_report(html_path: Path) -> Dict[str, Any]:
    """Parse a single HTML report file and extract QC metrics."""
    html_text = html_path.read_text(encoding="utf-8", errors="ignore")
    tables = _read_all_tables(html_path)

    sample_fallback = re.sub(r"_report$", "", html_path.stem)
    sample = _extract_sample_name_from_tables(tables, sample_fallback)

    # Merge kv maps from all 2-column tables; keep duplicates per key.
    merged: Dict[str, List[str]] = {}
    for df in tables:
        kv = _build_kv_maps_from_table(df)
        for k, vals in kv.items():
            merged.setdefault(k, []).extend(vals)

    assembled_reads = None
    if "Assembled reads" in merged and merged["Assembled reads"]:
        assembled_reads = _parse_value_before_slash(merged["Assembled reads"][0])

    # q30_rate: prefer After Filtering; else last q30_rate found
    q30_rate = _find_after_filtering_q30_rate(html_text)
    if q30_rate is None and "q30_rate" in merged and merged["q30_rate"]:
        q30_rate = _to_float(merged["q30_rate"][-1])

    # FASTP Duplication Rate appears as a header cell in your HTML, but read_html usually still captures it.
    dup_rate = None
    # try a few likely keys (depends how pandas parsed the th/td row)
    for key in ("FASTP Duplication Rate", "FASTP Duplication Rate in percenatage", "FASTP Duplication Rate in percentage"):
        if key in merged and merged[key]:
            dup_rate = _to_float(merged[key][-1])
            break
    if dup_rate is None:
        # fallback: regex from raw html
        m = re.search(r"FASTP Duplication Rate</th>\s*<td>\s*(" + _FLOAT_RE.pattern + r")\s*<", html_text, re.I)
        if m:
            dup_rate = float(m.group(1))

    # convert to percent
    fastp_duplication_rate_percent = dup_rate * 100 if dup_rate is not None else None

    mapped_reads = None
    mapped_reads_percent = None
    if "Mapped reads" in merged and merged["Mapped reads"]:
        mapped_reads = _to_int(merged["Mapped reads"][-1])
        if assembled_reads and assembled_reads > 0:
            mapped_reads_percent = (mapped_reads / assembled_reads) * 100

    reads_with_flanking = None
    if "Reads with flanking" in merged and merged["Reads with flanking"]:
        reads_with_flanking = _to_int(merged["Reads with flanking"][-1])

    assigned = None
    assigned_percentage = None
    if "Assigned sequences to valid peptides" in merged and merged["Assigned sequences to valid peptides"]:
        assigned = _to_int(merged["Assigned sequences to valid peptides"][-1])
        if mapped_reads and mapped_reads > 0:
            assigned_percentage = (assigned / mapped_reads) * 100

    unassigned = None
    if "Unassigned sequences to valid peptides" in merged and merged["Unassigned sequences to valid peptides"]:
        unassigned = _to_int(merged["Unassigned sequences to valid peptides"][-1])

    usable_reads_percent = None
    if assembled_reads and assigned is not None and assembled_reads > 0:
        usable_reads_percent = (assigned / assembled_reads) * 100

    return {
        "sample": sample,
        "assembled_reads": assembled_reads,
        "q30_rate_percent": (q30_rate * 100) if q30_rate is not None else None,  # 0.960017 -> 96.0017
        "fastp_duplication_rate_percent": fastp_duplication_rate_percent,
        "mapped_reads": mapped_reads_percent,
        "reads_with_flanking": reads_with_flanking,
        "assigned_sequences_to_valid_peptides": assigned_percentage,
        "unassigned_sequences_to_valid_peptides": unassigned,
        "usable_reads_percent": usable_reads_percent,
        "report_path": str(html_path),
    }


def collect_capscreen_reports(root_dir: str | Path, pattern: str = "*_report.html") -> pd.DataFrame:
    """
    Collect and parse all CapScreen HTML reports from a directory.
    
    Args:
        root_dir: Root directory to search for reports
        pattern: File pattern to match (default: "*_report.html")
        
    Returns:
        DataFrame with QC metrics for all samples
    """
    root = Path(root_dir)
    files = sorted(root.rglob(pattern))

    rows = []
    for fp in files:
        try:
            rows.append(_parse_single_report(fp))
        except Exception as e:
            logger.warning(f"Failed to parse report {fp}: {e}")
            rows.append(
                {
                    "sample": re.sub(r"_report$", "", fp.stem),
                    "report_path": str(fp),
                    "parse_error": f"{type(e).__name__}: {e}",
                }
            )

    df = pd.DataFrame(rows)

    # Optional: nicer ordering
    preferred_cols = [
        "sample",
        "assembled_reads",
        "q30_rate_percent",
        "fastp_duplication_rate_percent",
        "mapped_reads",
        "reads_with_flanking",
        "assigned_sequences_to_valid_peptides",
        "unassigned_sequences_to_valid_peptides",
        "usable_reads_percent",
        "report_path",
    ]
    cols = [c for c in preferred_cols if c in df.columns] + [c for c in df.columns if c not in preferred_cols]
    return df[cols]


def plot_assembled_reads(df: pd.DataFrame, output_file: Path):
    """Create bar plot for assembled reads by sample."""
    logger.info("Creating assembled reads plot...")
    
    try:
        # Filter out rows with missing assembled_reads
        df_plot = df[df['assembled_reads'].notna()].copy()
        if len(df_plot) == 0:
            logger.warning("No data with assembled_reads values, skipping plot")
            return
        
        # Sort samples by assembled reads
        df_sorted = df_plot.sort_values(by='assembled_reads', ascending=False)
        
        plt.figure(figsize=(8, 6), dpi=300)
        ax = sns.barplot(data=df_sorted, x='assembled_reads', y='sample', palette='viridis')
        ax.legend_.remove() if ax.legend_ else None
        plt.title('Assembled Reads by Sample')
        plt.xlabel('Assembled Reads')
        plt.ylabel('Sample')
        plt.tight_layout()
        plt.savefig(str(output_file), dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"Saved assembled reads plot to {output_file}")
    except Exception as e:
        logger.error(f"Failed to create assembled reads plot: {e}", exc_info=True)
        if plt.get_fignums():
            plt.close('all')
        raise


def plot_q30_rate(df: pd.DataFrame, output_file: Path):
    """Create bar plot for Q30 rate by sample with 95% threshold line."""
    logger.info("Creating Q30 rate plot...")
    
    try:
        # Filter out rows with missing q30_rate_percent
        df_plot = df[df['q30_rate_percent'].notna()].copy()
        if len(df_plot) == 0:
            logger.warning("No data with q30_rate_percent values, skipping plot")
            return
        
        # Sort samples by assembled reads
        df_sorted = df_plot.sort_values(by='assembled_reads', ascending=False)
        
        plt.figure(figsize=(8, 6), dpi=300)
        ax = sns.barplot(data=df_sorted, x='q30_rate_percent', y='sample', palette='viridis')
        ax.legend_.remove() if ax.legend_ else None
        plt.title('Q30 rate by sample')
        plt.xlabel('Q30 rate (%)')
        plt.ylabel('Samples')
        plt.axvline(
            x=95,
            linestyle="--",
            color="red",
            linewidth=1,
            label="95%"
        )
        plt.legend()
        plt.tight_layout()
        plt.savefig(str(output_file), dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"Saved Q30 rate plot to {output_file}")
    except Exception as e:
        logger.error(f"Failed to create Q30 rate plot: {e}", exc_info=True)
        if plt.get_fignums():
            plt.close('all')
        raise


def plot_assigned_sequences(df: pd.DataFrame, output_file: Path):
    """Create bar plot for percentage of reads assigned to valid peptides by sample with 60% threshold line."""
    logger.info("Creating assigned sequences plot...")
    
    try:
        # Filter out rows with missing assigned_sequences_to_valid_peptides
        df_plot = df[df['assigned_sequences_to_valid_peptides'].notna()].copy()
        if len(df_plot) == 0:
            logger.warning("No data with assigned_sequences_to_valid_peptides values, skipping plot")
            return
        
        # Sort samples by assigned sequences percentage
        df_sorted = df_plot.sort_values(by='assigned_sequences_to_valid_peptides', ascending=False)
        
        plt.figure(figsize=(8, 6), dpi=300)
        ax = sns.barplot(data=df_sorted, x='assigned_sequences_to_valid_peptides', y='sample', palette='viridis')
        ax.legend_.remove() if ax.legend_ else None
        plt.title('Percentage of reads assigned to valid peptides by sample')
        plt.xlabel('Reads assigned to valid peptides (%)')
        plt.ylabel('Samples')
        plt.axvline(
            x=60,
            linestyle="--",
            color="red",
            linewidth=1,
            label="60%"
        )
        plt.legend()
        plt.tight_layout()
        plt.savefig(str(output_file), dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"Saved assigned sequences plot to {output_file}")
    except Exception as e:
        logger.error(f"Failed to create assigned sequences plot: {e}", exc_info=True)
        if plt.get_fignums():
            plt.close('all')
        raise


def run_qc_analysis(reports_dir: Path, output_dir: Path, logger_instance: Optional[logging.Logger] = None) -> bool:
    """
    Run QC analysis on CapScreen reports.
    
    Args:
        reports_dir: Directory containing sample subdirectories with HTML reports
        output_dir: Directory where QC plots and summary CSV will be saved
        logger_instance: Optional logger instance
        
    Returns:
        True if QC completed successfully, False otherwise
    """
    if logger_instance is not None:
        global logger
        logger = logger_instance
    
    try:
        logger.info(f"Starting QC analysis on reports in {reports_dir}")
        
        # Collect all reports
        df = collect_capscreen_reports(reports_dir)
        
        if len(df) == 0:
            logger.warning("No HTML reports found for QC analysis")
            return False
        
        logger.info(f"Found {len(df)} report(s) to analyze")
        
        # Ensure output directory exists
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Save QC summary CSV
        qc_summary_file = output_dir / "capscreen_qc_summary.csv"
        df.to_csv(qc_summary_file, index=False)
        logger.info(f"Saved QC summary to {qc_summary_file}")
        
        # Create plots
        try:
            plot_assembled_reads(df, output_dir / "qc_assembled_reads.png")
        except Exception as e:
            logger.error(f"Failed to create assembled reads plot: {e}", exc_info=True)
        
        try:
            plot_q30_rate(df, output_dir / "qc_q30_rate.png")
        except Exception as e:
            logger.error(f"Failed to create Q30 rate plot: {e}", exc_info=True)
        
        try:
            plot_assigned_sequences(df, output_dir / "qc_assigned_sequences.png")
        except Exception as e:
            logger.error(f"Failed to create assigned sequences plot: {e}", exc_info=True)
        
        logger.info("QC analysis completed successfully")
        return True
        
    except Exception as e:
        logger.error(f"QC analysis failed: {e}", exc_info=True)
        return False

